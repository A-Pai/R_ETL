
# 加速神器：data.table

如果你已经看到这个章节，并且对前面的内容了如指掌，能够融会贯通，那么恭喜你！你已经具备数据清洗的技能了，而且能够随心所欲地在R中操纵数据了。前一章节我们讲了Spark与R的连接，它的目标就是解决"大数据"的问题。如果在日常工作、学习中，你接触到的数据都是兆级（M）的，那么你可以止步于此，不断在工作中反复熟悉本书的内容。  
但是，如果你在现实工作中，经常要面对几百兆甚至千兆级（G）的数据，那么就需要更上一层楼了。因为现实工作中，时间就是金钱。Speed really matters!（速度很重要！）我本来不想在本书中提data.table，因为它并不简单。如果大家回顾我们学过的前面的章节，大家应该都会有这个感觉：简单到爆炸！以前居然不知道R中有这么好用的如此便捷的工具。但是接下来我们将要进阶的内容，算不得容易。不过大家如果都坚信自己掌握了前面的内容，再来学习data.table的话，那么也不会特别难。

  
## data.table是什么
data.table是Matt Dowle做的一个包，它能够完成的功能，跟本书前面章节所讲的基本类似。截止至2018年11月，它在Stack Overflow关于R包的内容中，被提到的次数排名第4，在Github上评星系统中排名第10。具有至少650个包需要依赖这个包，也就是如果要用到这650个包就必须先安装data.table。这个包在2006年完成了1.0的版本，一直维护至今，笔者写下这些文字的时候，它正在开发1.11.9版本。在R语言中，很多人都是因为解决某一些小的问题，写一个包，然后解决掉，感觉可以告一段落了，就不会继续维护了。但是这个包能够存活10年以上，而且还在持续更新，可见它用户群体之广，影响力之深远。
![data.table的Logo](https://raw.githubusercontent.com/wiki/Rdatatable/data.table/icons/sticker.png)

如果把它归结为一个产品，那么一个好的产品的功能大抵能够用一句话来总结。作者在他的Github主页中把他的包总结为：“ It provides a high-performance version of base R's data.frame with syntax and feature enhancements for ease of use, convenience and programming speed”。也就是说，从本质上来讲它是R语言data.frame的强大辅助工具，易用、便捷、快！

## 为什么要用data.table
目前我们已经学习了前面的所有内容，我们对数据预处理、数据清洗要做的内容有了基本的了解。尽管在特性上有所不同，但是data.table最重要的核心功能，依旧是我们前面提到的包括过滤、分组、汇总在内的各种ETL操作（或者叫做表格透视操作）。大家可能会问了，既然都已经会了前面如此便捷的一套工具，为什么还要学习另一套。只因一个字：快！
笔者其实是一个非常懒惰的人，也就是会了一个东西，如果能够完成一个任务，而且足够好，一般不会花成本学习另一个完成同样任务东西。我们前面所学的内容，属于tidyverse的生态系统，大多是属于dplyr包的内容。我毫不掩饰对它的赞美，因为它简洁、逻辑清晰，而且还能够与其他工具联合使用达到事半功倍的效果。尽管如此，data.table还是进入了我的视野，因为笔者有时候需要对规模非常大的数据进行操作，这时候等待的时间就非常长。长到什么地步？长到我可以上网查查有什么方法能够加速，长到我可以发现data.table，并且长到我都能够学会data.table并且灵活地运用了。天下武功，唯快不破。互联网时代，快鱼吃慢鱼，呼唤敏捷开发，迅速迭代。速度，真的就是那么重要。

![面对50G数据时data.table与其他解决方案的速度比较图（图片来自官网）](G:\College_of_big_data\R_SQL\初稿\data.table_50g.png)

## dplyr vs. data.table
在入坑之前，我们先看个热闹。其实早在2014年初，我们前面学习的dplyr包与data.table包在Stack Overflow中引发了一场相当热烈的争论（原文可参考<https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly?rq=1>）。原文题目是：data.table vs dplyr: can one do something well the other can't or does poorly? （翻译过来就是，哪个包能够完成对方无法完成的东西，或者是同样的任务，谁完成得更好？）两个包的使用者、作者、合作者汇聚一堂，在小小的提问中八仙过海各显神通，通过案例比较来说明自身相比对方具有更多优越性。懂技术的人，打口水仗也是非常有水平，文辞之尖酸隐晦，案例之精巧深入，堪称典范。  
这里就不深究这场争论了，我认为在技术界的百花齐放百家争鸣是一件相当美好的事情。正如R与Python之争，争论本身是没有意义的。语言都是工具，各种包也是工具，都是为了优秀地完成任务而存在的，有特点之不同，但不应有优劣之分。谈一下我“客观”的感受：  
1.dplyr就是比data.table更容易学习，更容易写出高效的代码，可读性也更强。在争论中，dplyr一派称之为“Syntax”，我理解为语法结构。它能够最大限度节省用户的编程时间，善莫大焉！  
2.data.table更快，就数据导入而言，fread函数的速度就是快到爆炸；其他操作也是一样的，同样的操作data.table只会比dplyr更快，从来不会更慢。至于快多少，取决于我们要解决的任务和计算机的配置。也许小的任务，大家速度差不多，因为基本都是秒级运算，所以没差。但是数据量一旦提高，这个差距是相当明显的。  
所以为什么两家不合并起来做个又快又好的东西呢？谈何容易！两个包在设计之初就有不同的哲学理念，dplyr是希望能够把复杂的操作，分解为一步一步简单的操作，大家在前面的案例中也看到，我们每一行其实只解决一个不能够再简化的问题，只是用“%>%”连在一起，最后就解决了个大问题。但是先做哪一步，后做哪一步，都是十分明晰的，因此它简单易学。另外它的语法也非常直观，我们现在基本能够做到“见名知意”。使用data.table的用户可能会争辩，认为用“[][]”一样实现了管道操作，其实这是不恰当的，它的设计结构（dt[i,j,by]）就决定了它每一步没办法简化无法继续简化的一步，因为它要一步能够完成三个操作，这三个操作无法用“[][]”分解开来。不过正因为它能够同时考虑多个内容，在完成一些步骤时它能够一次有更多的设定，从而优化内部结构，达到更高的速度。了解即时编译（JIT,Just-In-Time）原理可能有助于对这个底层知识的理解，但是我们这里只聚焦于实际使用，不再继续深究底层的内容。  
综上，就笔者的感受而言，dplyr语法格式简洁优雅，易写易读，这是为什么本书要把这方面的内容放在最前面奉献给大家；data.table不提别的，就是快！如果对速度没有要求的用户，比如做一点小小的研究探索，那么dplyr完全够用了。但是如果要天天对着G级以上的数据做操作，那么data.table还是要学一下的。如果数据不是分布式存储的，它甚至能够直接跟Spark叫板！


## 应该如何入坑data.table
如果把data.table形容得很难，也是不对的。事实上，很多资深data.table用户的体会是，当你理解了这个逻辑结构之后，写起来相当容易！事实上在官网上（<https://github.com/Rdatatable/data.table/wiki>），作者通过一页纸的内容就写清楚了data.table的各种功用和对应的语法结构。不过它肯定不会比dplyr容易，还是需要记忆很多东西才能够灵活地使用。此外，data.table的代码可读性不是特别强，需要扎扎实实地实践一段时间，才能够成为熟手。   
如何入坑？如果从头开始学，还是比较困难的。但是如果你已经熟练掌握了本书前面的内容，也就是说你已经会了dplyr的话，要学这些就不要太简单了。正如dplyr能够直接“翻译”成SQL，其实对于相同的操作来说，我们也可以把data.table“翻译”成dplyr。如果你认为dplyr非常容易理解的话（也就是本书先前章节的内容），那么恭喜你，data.table离你只有一步之遥了。在后面关于加速的章节中，我们会再次展示如何进行数据操纵。我们会给出具体操作的解释，以及dplyr和data.table的的实现方案，大家可以对照着反复练习，一方面加深对dplyr的理解，另一方面掌握这些操作如何在data.table中高速实现。  
想要速度的么？跟我走，带你飞！  

## 小结
本章简要介绍了data.table是什么工具，以及它与dplyr的对比。我们知道在面对大数据的时候，data.table能够提供更加快的速度。如果你已经充分掌握了前面的dplyr操作，充分理解数据预处理的本质是在做分组、汇总、筛选、排序等操作，接下来的data.table之旅将会非常轻松。加油！


